# NaverAIBoostCamp_7ê¸°_paper

[![Since](https://img.shields.io/badge/since-2025.01.01-333333.svg?style=flat-square)](https://github.com/2JAE22/AI_Tech-paper)
[![author](https://img.shields.io/badge/author-2JAE22-0066FF.svg?style=flat-square)](https://github.com/2JAE22)
[![LICENSE](https://img.shields.io/github/license/2JAE22/AI_Tech-paper.svg?style=flat-square)](https://github.com/2JAE22/AI_Tech-paper/blob/main/LICENSE)
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2F2JAE22%2FAI_Tech-paper%2Fhit-counter&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)
[![All Contributors](https://img.shields.io/badge/all_contributors-2?style=flat-square)](https://github.com/2JAE22/AI_Tech-paper/graphs/contributors)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-FF66FF.svg?style=flat-square)](http://makeapullrequest.com)

[![Watch on GitHub](https://img.shields.io/github/watchers/2JAE22/AI_Tech-paper.svg?style=social)](https://github.com/2JAE22/AI_Tech-paper/watchers)
[![Star on GitHub](https://img.shields.io/github/stars/2JAE22/AI_Tech-paper.svg?style=social)](https://github.com/2JAE22/AI_Tech-paper/stargazers)
[![Fork on GitHub](https://img.shields.io/github/forks/2JAE22/AI_Tech-paper.svg?style=social)](https://github.com/2JAE22/AI_Tech-paper/network/members)



<br> 

**Collaborator**

[<img src="https://avatars.githubusercontent.com/u/87936538?v=4" width="100">](https://github.com/2JAE22)  
[GitHub](https://github.com/2JAE22)

<br>

**Commit convention rule** : ë‚ ì§œ-[ì£¼ì œ]-ë‚´ìš©-ìƒíƒœ

`ex) 2025-01-01 [CV íŠ¸ë™ì¶”ê°€] only_paper Add/Update/Delete`

<br>

ì˜ëª»ëœ ë‚´ìš©ì€ [ì´ìŠˆ](https://github.com/2JAE22/AI_Tech-paper/issues)ì™€ [PR](https://github.com/2JAE22/AI_Tech-paper/pulls)ë¡œ ì•Œë ¤ì£¼ì„¸ìš” ğŸ’¡

<br>



<center>ğŸ™ë„ì›€ì„ ì£¼ì‹  ë¶„ë“¤ğŸ™</center>

<br>
<br>

<a href="https://github.com/2JAE22/AI_Tech-paper/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=2JAE22/AI_Tech-paper" />
</a>

<br>


#### ë” ì¢‹ì€ ì»¨í…ì¸ ë¥¼ ì œê³µë°›ê¸¸ ì›í•œë‹¤ë©´ [ğŸ’–í›„ì›í•˜ê¸°!!ğŸ’](https://github.com/sponsors/2JAE22)

# 1. ğŸ“ŒIntroduction
NaverAIboostCampì—ì„œ ì†Œê°œí•œ ë…¼ë¬¸ë“¤ì„ ì£¼ì œë³„ë¡œ ì •ë¦¬í•œ í´ë”ì…ë‹ˆë‹¤.
í˜„ì¬ëŠ” CV(Computer Vision) íŠ¸ë™ì˜ ë…¼ë¬¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•˜ê³  ìˆìœ¼ë©°, ì¶”í›„ ëª¨ë“  íŠ¸ë™ìœ¼ë¡œ í™•ì¥í•  ì˜ˆì •ì…ë‹ˆë‹¤.

# 2ì—ì„œ 5ê¹Œì§€ëŠ” ë…¼ë¬¸ë§Œ ìˆìŠµë‹ˆë‹¤.
- [6](#6-further-readingì—-ìˆì—ˆë˜-ê²ƒë“¤)ë¶€í„° ë…¼ë¬¸ì™¸ì˜ ì‚¬ì´íŠ¸ë“¤ì„ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.

# 2. ğŸ“ŒCV íŠ¸ë™ ì •ë¦¬(Only Paper)
## 2.1 CV ì´ë¡ 
- [VGGNet](https://arxiv.org/abs/1409.1556)  
- [ResNet](https://arxiv.org/abs/1512.03385)  
- [ViT](https://arxiv.org/abs/2010.11929)
- [Grad-CAM](https://arxiv.org/abs/1610.02391)
- [mixup](https://arxiv.org/abs/1710.09412)
- [CutMix](https://arxiv.org/abs/1905.04899)
- [Fully Convolutional Networks for Semantic Segmentation](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)
- [SAM](https://arxiv.org/pdf/2304.02643)
- [DETR](https://arxiv.org/pdf/2005.12872)
- [Real-World Single Image Super-Resolution: A New Benchmark and A New Model](https://arxiv.org/abs/1904.00523)
- [Real-World Blur Dataset for Learning and Benchmarking Deblurring Algorithms](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123700188.pdf)
- [Blind Super-Resolution Kernel Estimation using an Internal-GAN](https://arxiv.org/abs/1909.06581)
- [SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://arxiv.org/abs/2404.04319)
- [CLIP huggingface implementation](https://github.com/huggingface/transformers/blob/main/src/transformers/models/clip/modeling_clip.py)
- [ImageBIND official implementation](https://github.com/facebookresearch/ImageBind)
- [LanguageBIND](https://arxiv.org/abs/2310.01852)
- [Flamingo pytorch implementation](https://github.com/lucidrains/flamingo-pytorch/blob/main/flamingo_pytorch/flamingo_pytorch.py)
- [LLaVA](https://llava-vl.github.io/)
- [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/abs/2201.12086)
- [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)
- [DDPM](https://arxiv.org/abs/2006.11239)
- [LDM (Stable Diffusion)](https://arxiv.org/abs/2112.10752)
- [DDIM](https://arxiv.org/abs/2010.02502) 
- [3D MACHINE LEARNING](https://www.antoinetlc.com/blog-summary/3d-data-representations)
- [Mesh R-CNN](https://arxiv.org/abs/1906.02739)
- [NeRF](https://arxiv.org/abs/2003.08934)
- [3DGS](https://arxiv.org/abs/2308.04079)
- [DreamFusion](https://arxiv.org/abs/2209.14988)
- [Loper et al., SMPL: A Skinned Multi-Person Linear Model: SIGGRAPH 2015.](https://dl.acm.org/doi/10.1145/2816795.2818013)
- [Bogo et al., Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image: ECCV 2016.](https://arxiv.org/abs/1607.08128)
- [Anguelov et al., SCAPE: Shape Completion and Animation of People: SIGGRAPH 2005.](https://dl.acm.org/doi/10.1145/1073204.1073207)


## 2.2 CV ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [A survey on Image Data Augmentation for Deep Learning](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)
- [AutoAugment: Learning Augmentation Strategies from Data](https://arxiv.org/abs/1805.09501)
- [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/abs/1909.13719)
- [Fine-Grained Image Analysis with Deep Learning: A Survey](https://arxiv.org/abs/2111.06119)
- [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
- [CoAtNet: Marrying Convolution and Attention for All Data Sizes](https://arxiv.org/abs/2106.04803)
- [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases](https://arxiv.org/abs/2103.10697)
- [Multimodal Learning with Transformers: A Survey](https://arxiv.org/abs/2206.06488)
- [Self-supervised Learning: Generative or Contrastive](https://arxiv.org/abs/2006.08218)
- [Ensemble deep learning: A review](https://arxiv.org/abs/2104.02395)
  
## 2.3 Object Detection
- [R-CNN](https://arxiv.org/abs/1311.2524)
- [Fast R-CNN](https://arxiv.org/abs/1504.08083)
- [Faster R-CNN](https://arxiv.org/abs/1506.01497)
- [SPPNet](https://arxiv.org/abs/1406.4729)
- [FPN](https://arxiv.org/abs/1612.03144)
- [PAFPN](https://arxiv.org/abs/1803.01534)
- [DetectoRS](https://arxiv.org/abs/2006.02334)
- [EfficientDet (BiFPN)](https://arxiv.org/abs/1911.09070v7)
- [NasFPN](https://arxiv.org/abs/1904.07392)
- [AugFPN](https://arxiv.org/abs/1912.05384)
- [YOLO survey](https://arxiv.org/abs/2304.00501)
- [Retinanet (focal loss)](https://arxiv.org/abs/1708.02002)
- [SSD](https://arxiv.org/abs/1512.02325)
- [EfficientNet](https://arxiv.org/abs/1905.11946)
- [EfficientDet](https://arxiv.org/abs/1911.09070)
- [DCN](https://arxiv.org/abs/1703.06211)
- [DETR](https://arxiv.org/abs/2005.12872)
- [Swin](https://arxiv.org/abs/2103.14030)
- [YOLO v4](https://arxiv.org/abs/2004.10934)
- [M2Det](https://arxiv.org/abs/1811.04533)
- [CornerNet](https://arxiv.org/abs/1808.01244)

## 2.4 Data-Centric AI
- [DMLR](https://openreview.net/pdf?id=2kpu78QdeE)
- [Convolutional Character Networks](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xing_Convolutional_Character_Networks_ICCV_2019_paper.pdf)
- [EAST](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_EAST_An_Efficient_CVPR_2017_paper.pdf)
- [Data and its (dis)contents: A survey of dataset development and use in machine learning research](https://www.sciencedirect.com/science/article/pii/S2666389921001847)
- [Human-In-The-Loopì— ëŒ€í•œ survey ë…¼ë¬¸](https://www.sciencedirect.com/science/article/abs/pii/S0167739X22001790?casa_token=5poWCKizHjIAAAAA:Z8eK3GMWCCwOncUmdz2J8JHGNYAx3N4MW_31Uq3CnWVQN2C6RXXtOqc50GveYglcudc9TiwhYKk)
- [ë‹¤ì–‘í•œ taskì— ì ìš© ê°€ëŠ¥í•œ IAAì— ê´€í•œ ë…¼ë¬¸](https://dl.acm.org/doi/10.1145/3485447.3512242)
- [LLMì„ í™œìš©í•œ data annotationì— ê´€í•œ survey ë…¼ë¬¸](https://arxiv.org/abs/2402.13446)
- [A survey on Image Data Augmentation for Deep Learning](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)
- [A survey of synthetic data augmentation methods in computer vision](https://arxiv.org/abs/2403.10075)



## 2.5 Semantic Segmentation
- [FCN](https://arxiv.org/abs/1411.4038)
- [DeconvNet](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.pdf)
- [SegNet](https://arxiv.org/pdf/1511.00561)
- [FCDenseNet](https://arxiv.org/pdf/1611.09326)
- [Unet](https://arxiv.org/abs/1505.04597)
- [DeepLabv1](https://arxiv.org/pdf/1412.7062)
- [DilatedNet ](https://arxiv.org/abs/1511.07122)
- [DeepLabv2](https://arxiv.org/pdf/1606.00915)
- [PSPNet](https://arxiv.org/pdf/1612.01105)
- [DeepLabv3](https://arxiv.org/pdf/1706.05587)
- [DeepLabv3+](https://arxiv.org/pdf/1802.02611)
- [Unet](https://arxiv.org/abs/1505.04597)
- [Unet++](https://arxiv.org/pdf/1912.05074)
- [Unet3+](https://arxiv.org/abs/2004.08790)
- [EfficientUnet](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w22/Baheti_Eff-UNet_A_Novel_Architecture_for_Semantic_Segmentation_in_Unstructured_Environment_CVPRW_2020_paper.pdf)
- [DenseUnet](https://arxiv.org/abs/1611.09326)
- [ResidualUnet](https://arxiv.org/pdf/1711.10684)
- [SWA](https://arxiv.org/abs/1803.05407)
- [HRNet](https://arxiv.org/pdf/1908.07919)
- [SegFormer](https://arxiv.org/pdf/2105.15203)
- [ViT](https://arxiv.org/pdf/2010.11929)
- [Weakly Supervised Object Localization and Detection: A Survey](https://arxiv.org/abs/2104.07918)

# 3. ğŸ“ŒNLP íŠ¸ë™ ì •ë¦¬(Only Paper)
## 3.1 NLP ì´ë¡ 
- [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)
- [GloVe: Global Vectors for Word Representation](https://aclanthology.org/D14-1162/)
- [LSTM](https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext)
- [Highway Networks](https://arxiv.org/abs/1505.00387)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)
- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
- [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)
- [Sparse is Enough in Scaling Transformers](https://openreview.net/pdf?id=-b5OSCydOMe)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Layer Normalization](https://arxiv.org/abs/1607.06450)
- [Group Normalization](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yuxin_Wu_Group_Normalization_ECCV_2018_paper.pdf)
- [Attention is not Explanation](https://arxiv.org/pdf/1902.10186)
- [Attention is not not Explanation](https://aclanthology.org/D19-1002.pdf)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)
- [Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/abs/1609.08144)
- [Neural Network Acceptability Judgments](https://arxiv.org/abs/1805.12471)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](https://arxiv.org/abs/1704.05426)
- [SQuAD: 100,000+ Questions for Machine Comprehension of Text](https://arxiv.org/abs/1606.05250)
- [Hierarchical Neural Story Generation](https://arxiv.org/abs/1805.04833)
- [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)

  
## 3.2 NLP ê¸°ì´ˆ í”„ë¡œì íŠ¸
## 3.3 MRC
## 3.4 Data-Centric NLP
## 3.5 Generative for NLP


# 4. ğŸ“ŒRecsys íŠ¸ë™ ì •ë¦¬(Only Paper)
## 4.1 Recsys ì´ë¡ 
## 4.2 ML ê¸°ì´ˆ í”„ë¡œì íŠ¸
## 4.3 Competitive DS
## 4.4 RecSys ê¸°ì´ˆí”„ë¡œì íŠ¸
## 4.5 Movie Rec



# 5. ğŸ“Œê³µí†µ ê°•ì˜ì—ì„œ ì†Œê°œí•œ ë…¼ë¬¸ ì •ë¦¬
## 5.1 Generative AI
- [LLM Survey ë…¼ë¬¸ (2023)](https://arxiv.org/abs/2303.18223)
- [GAN Survey ë…¼ë¬¸ (2020)](https://arxiv.org/abs/1906.01529)
- [Diffusion Models Survey ë…¼ë¬¸ (2024)](https://arxiv.org/abs/2209.00796)
- [RLHF ì œì•ˆ ë…¼ë¬¸](https://arxiv.org/abs/2203.02155)
- [Large Language Model ì„œë² ì´ ë…¼ë¬¸](https://arxiv.org/abs/2303.18223)
- [GPT-3 ë…¼ë¬¸](https://arxiv.org/abs/2005.14165)
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
- [Self-Instruct ë…¼ë¬¸](https://arxiv.org/abs/2212.10560)
- [Self-Rewarding ë…¼ë¬¸](https://arxiv.org/pdf/2401.10020)
- [GAN ë…¼ë¬¸](https://arxiv.org/abs/1406.2661)
- [cGAN ë…¼ë¬¸](https://arxiv.org/abs/1411.1784)
- [Pix2Pix ë…¼ë¬¸](https://arxiv.org/abs/1611.07004)
- [CycleGAN ë…¼ë¬¸](https://arxiv.org/abs/1703.10593)
- [StarGAN ë…¼ë¬¸](https://arxiv.org/abs/1711.09020)
- [ProgressiveGAN ë…¼ë¬¸](https://arxiv.org/abs/1710.10196)
- [StyleGAN ë…¼ë¬¸](https://arxiv.org/abs/1812.04948)
- [VAE ë…¼ë¬¸](https://arxiv.org/abs/1312.6114)
- [VQ-VAE ë…¼ë¬¸](https://arxiv.org/abs/1711.00937)
- [DDPM ë…¼ë¬¸](https://arxiv.org/abs/2006.11239)
- [DDIM ë…¼ë¬¸](https://arxiv.org/abs/2010.02502)
- [Classifier Guidance ë…¼ë¬¸](https://arxiv.org/abs/2105.05233)
- [Classifier-free Guidance ë…¼ë¬¸](https://arxiv.org/abs/2207.12598)
- [LDM ë…¼ë¬¸](https://arxiv.org/abs/2112.10752)
- [Latent Diffusion Model](https://arxiv.org/abs/2112.10752)
- [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)
- [SDXL Turbo (Adversarial Diffusion Distillation)](https://arxiv.org/abs/2311.17042)




## 5.2 Product Serving
- paper ì—†ìŒ


## 5.3 ìµœì í™”/ê²½ëŸ‰í™”
- [Rethinking the Value of Network Pruning](https://arxiv.org/abs/1810.05270)
- [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](https://arxiv.org/abs/1712.05877)
- [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks:](https://arxiv.org/abs/1803.03635)
- [Pruning Convolutional Neural Networks for Resource Efficient Inference](https://arxiv.org/abs/1611.06440)
- [Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning](https://arxiv.org/abs/2002.08307)
- [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)
- [Parameter-Efficient Transfer Learning for NLP ](https://arxiv.org/pdf/1902.00751)
- [Prompt tuning ](https://arxiv.org/pdf/2104.08691)
- [Prefix tuning ](https://arxiv.org/pdf/2101.00190)
- [AdapterFusion: Non-Destructive Task Composition for Transfer Learning](https://arxiv.org/abs/2005.00247)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)

---

**ì—¬ê¸°ì„œë¶€í„°ëŠ” ë…¼ë¬¸ì™¸ì˜ ì½ì„ê±°ë¦¬ë“¤ë¡œ ìˆì—ˆë˜ ê²ƒë“¤ì„ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.**
# 6. ğŸ“ŒFurther Readingì— ìˆì—ˆë˜ ê²ƒë“¤.
## 6.1 ê³µí†µì½”ìŠ¤
### 6.1.1 Pytorch
- [Introduction to PyTorch â€” PyTorch Tutorials documentation](https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html)
- [í…ì„œ(Tensor) â€” íŒŒì´í† ì¹˜ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ (PyTorch tutorials in Korean)](https://tutorials.pytorch.kr/beginner/introyt/introyt1_tutorial.html)
- [torch.Tensor â€” PyTorch documentation](https://pytorch.org/docs/main/tensors.html)
- [ë¶€ë™ì†Œìˆ˜ì  - ë°±ê³¼ì‚¬ì „](https://ko.wikipedia.org/wiki/%EB%B6%80%EB%8F%99%EC%86%8C%EC%88%98%EC%A0%90)
- [torch.randn â€” PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn)
- [torch.Tensor â€” PyTorch documentation](https://pytorch.org/docs/main/tensors.html)
- [GPUì™€ AI - ë„¤ì´ë²„ ì§€ì‹ë°±ê³¼](https://terms.naver.com/entry.naver?docId=2080143&cid=50305&categoryId=50305)
- [torch.Tensor.view â€” PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.Tensor.view.html#torch-tensor-view)
- [torch.reshape â€” PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.reshape.html#torch-reshape)
- [Difference between view, reshape, transpose and permute in PyTorch](https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/)
- [torch.squeeze â€” PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.squeeze.html#torch-squeeze)
- [Tensor ëª¨ì–‘ ì„¤ëª…](https://velog.io/@jk01019/broadcastto-repeat-repeatinterleave-view-reshape-expand-expandas-tile-flatten-unsqueeze-squeeze-stack-cat-d1n8ersb)
- [$L_p$ norm](https://en.m.wikipedia.org/wiki/Lp_space)
- [ì„ í˜•íšŒê·€](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)
- [ê²½ì‚¬í•˜ê°•ë²• í•™ìŠµë°©ë²•](https://www.youtube.com/watch?v=IHZwWFHWa-w)
- [Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)
- [PyTorch DataLoader â€” PyTorch main documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)
- [BCELoss â€” PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)
- [BCEWithLogitsLoss â€” PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss)
- [CrossEntropyLoss â€” PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)

### 6.1.2 ML LifeCycle
- [A survey on Image Data Augmentation for Deep Learning ](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0) 
- [Clipping](https://arxiv.org/pdf/1211.5063) 
- [LSTM â€” PyTorch main documentation ](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) 
- [Attention Is All You Need ](https://arxiv.org/pdf/1706.03762) 
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding ](https://arxiv.org/pdf/1810.04805) 
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale ](https://arxiv.org/pdf/2010.11929) 


### 6.1.3 EDA & DataViz
- [[Harvard Business Review] Boost Your Teamâ€™s Data Literacy](https://hbr.org/2020/02/boost-your-teams-data-literacy)
- [[Sequoia Capital] Why Data Science Matters](https://medium.com/sequoia-capital/why-data-science-matters-ee583f785a55)
- [[Sequoia Capital] Role of Data Scientist](https://medium.com/sequoia-capital/five-core-skills-of-a-data-scientist-fc044014fafa)
- [ë°ì´í„° ì‹œê°í™” êµê³¼ì„œ (í´ë¼ìš°ìŠ¤ ìœŒì¼€ ì €)](https://clauswilke.com/dataviz/index.html)
- [Data Viz Project](https://datavizproject.com/)
- [Misleading Data Visualization](https://pressbooks.library.torontomu.ca/criticaldataliteracy/chapter/misleading-data-visualizations/)
- [[The Economists] Mistakes, weâ€™ve drawn a few](https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368)
- [[Google ML Course] Types of Bias](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias?hl=ko)
- [[Github] Awesome Feature Engineering](https://github.com/aikho/awesome-feature-engineering)
- [[ì„œìš¸ëŒ€ AI ì—°êµ¬ì›] ë‹¤ì°¨ì› ë°ì´í„° ì‹œê°í™”ì™€ AI (ì»´í“¨í„°ê³µí•™ë¶€ ì„œì§„ìš± êµìˆ˜)](https://www.youtube.com/watch?v=ymA1spEAd7M)
- [[Distill] How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)
- [Forecasting: Principles & Practice](https://otexts.com/fppkr/arima.html)
- [Hugging Face - NLP Course](https://huggingface.co/learn/nlp-course/ko/chapter1/2?fw=pt)
- [Text Visualization Browser](https://textvis.lnu.se/)
- [[Github] eugeneyan/applied-ml](https://github.com/eugeneyan/applied-ml)
- [[Material Design] Data Visualization](https://m2.material.io/design/communication/data-visualization.html)
- [ì˜ëª» ì‚¬ìš©ëœ ì‹œê°í™” ëª¨ìŒ WTF.viz](https://viz.wtf/)
- [Startup Metrics for Pirates: AARRR! - Dave McClure](https://www.youtube.com/watch?v=irjgfW0BIrw)
- [ë°ì´í„° ì‹œê°í™”, ì¸ì§€ê³¼í•™ì„ ë§Œë‚˜ë‹¤ ](https://www.yes24.com/Product/Goods/19013968)
- [ë„ë„ë“œ ë…¸ë§Œì˜ UX ë””ìì¸ íŠ¹ê°• ](https://www.yes24.com/Product/Goods/59673763)
- [UX/UIì˜ 10ê°€ì§€ ì‹¬ë¦¬í•™ ë²•ì¹™ ](https://product.kyobobook.co.kr/detail/S000212939982)

### 6.1.4 AI ê°œë°œ ê¸°ì´ˆ
- ["Clean Code: A Handbook of Agile Software Craftsmanship" by Robert C. Martin:](https://www.oreilly.com/library/view/clean-code-a/9780136083238/)
- ["Design Patterns: Elements of Reusable Object-Oriented Software" by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissidesn](https://www.oreilly.com/library/view/design-patterns-elements/0201633612/)
- ["ëª¨ë˜ ë¦¬ëˆ…ìŠ¤ êµê³¼ì„œ" by ë§ˆì´í´ í•˜ìš°ì„¼ë¸”ë¼ìŠ¤](https://product.kyobobook.co.kr/detail/S000210138053)
- ["The Linux Command Line" by William Shotts:](https://wiki.lib.sun.ac.za/images/c/ca/TLCL-13.07.pdf)
- [Streamlit ê³µì‹ ë¬¸ì„œ](https://docs.streamlit.io/)
- [Python 3.x Docs: Virtual Environments and Packages](https://docs.python.org/3/tutorial/venv.html)



## 6.2 CV
### 6.2.1 CV ì´ë¡    
- [í•œê²¨ë¡€ ë‰´ìŠ¤ â€œë¹Œê²Œì´ì¸ ë„ ê°íƒ„í•œ ìµœì˜ˆì§„ êµìˆ˜, ìƒì„±í˜• AI í•™ìŠµ ë°ì´í„° ê³µê°œí•´ì•¼"](https://www.hani.co.kr/arti/economy/economy_general/1128825.html)




### 6.2.2 CV ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [Kaggle Competition](https://www.kaggle.com/competitions)
- [Image file format](https://en.wikipedia.org/wiki/Image_file_format)
- [Multilabel Image Classification Using Deep Learning](https://www.mathworks.com/help/deeplearning/ug/multilabel-image-classification-using-deep-learning.html)
- [Training with Pytorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)
- [Pytorch: Automatic Mixed Precision ](https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html)
- [Nvidia: Mixed-Precision-Training](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html)
- [Tensorboard](https://www.tensorflow.org/tensorboard/get_started?hl=ko)
- [WandB](https://wandb.ai/site/ko/)  

### 6.2.3 Object Detection
- [mmdetection github](https://github.com/open-mmlab/mmdetection)
- [detectron2 github](https://github.com/facebookresearch/detectron2)
- [Paperswithcode Object Detection](https://paperswithcode.com/task/object-detection)
- [Kaggle](https://www.kaggle.com/competitions)

### 6.2.4 Data-Centric AI
- [AI ìµœì‹  í™œìš© ì‚¬ë¡€](https://www.content.upstage.ai/blog/insight/examples-of-artificial-intelligence)
- [í˜„ì‹¤ ì„¸ê³„ì—ì„œì˜ ë°ì´í„°ì¤‘ì‹¬ AI](https://ko.upstage.ai/blog/tech/data-centric-ai-in-the-real-world)
- [SynthText in the Wild Dataset](https://www.robots.ox.ac.uk/~vgg/data/scenetext/)
- [Tesseract (Off-the-shelf OCR open source)](https://tesseract-ocr.github.io/)
- [Data annotationì— ëŒ€í•œ OpenCVì˜ blogpost](https://opencv.org/blog/data-annotation/)


### 6.2.5 Semantic Segmentation
- [Segmentation models library](https://github.com/qubvel/segmentation_models)

## 6.3 NLP
### 6.3.1 NLP ì´ë¡ 
- [Byte-Pair Encoding tokenization](https://huggingface.co/learn/nlp-course/en/chapter6/5)
- [The Illustrated Word2vec](https://jalammar.github.io/illustrated-word2vec/)
- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- [cs231n Lecture 10: Recurrent Neural Networks](https://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)
- [The Exploding and Vanishing Gradients Problem in Time Series](https://medium.com/metaor-artificial-intelligence/the-exploding-and-vanishing-gradients-problem-in-time-series-6b87d558d22)
- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [BertViz: Visualize Attention in NLP Models](https://github.com/jessevig/bertviz)
- [Foundations of NLP Explained Visually: Beam Search, How It Works](https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24)
- [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate)

  
### 6.3.2 NLP ê¸°ì´ˆ í”„ë¡œì íŠ¸

### 6.3.3 MRC
### 6.3.4 Data-Centric NLP
### 6.3.5 Generative for NLP

## 6.4 Recsys
### 6.4.1 Recsys ì´ë¡ 
### 6.4.2 ML ê¸°ì´ˆ í”„ë¡œì íŠ¸
### 6.4.3 Competitive DS
### 6.4.4 RecSys ê¸°ì´ˆí”„ë¡œì íŠ¸
### 6.4.5 Movie Rec

## 6.5 Generative AI
- [LLM ëª¨ë¸ íŠœë‹, í•˜ë‚˜ì˜ GPUë¡œ ê°€ëŠ¥í• ê¹Œ? Parameter Efficient Fine-Tuning(PEFT)ì„ ì†Œê°œí•©ë‹ˆë‹¤!](https://devocean.sk.com/blog/techBoardDetail.do?ID=164779&boardType=techBlog)
- [Alpaca í™ˆí˜ì´ì§€](https://crfm.stanford.edu/2023/03/13/alpaca.html)


## 6.6 Product Serving
- [Uberì˜ Michelangelo í”Œë«í¼ì— ê´€í•œ ê¸€ë¡œ, ëŒ€ê·œëª¨ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„œë¹™ ë°©ë²•ì— ëŒ€í•œ í†µì°°ì„ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://www.uber.com/en-KR/blog/scaling-michelangelo/)
- [Machine learning is going real-time](https://huyenchip.com/2020/12/27/real-time-machine-learning.html)
- [ì˜ì¹´ì˜ Airflow êµ¬ì¶•ê¸°](https://tech.socarcorp.kr/data/2021/06/01/data-engineering-with-airflow.html)
- [ì˜ì¹´ì˜ Airflow êµ¬ì¶•ê¸°2](https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html)
- [ë²„í‚·í”Œë ˆì´ìŠ¤ Airflow ë„ì…ê¸°](https://www.bucketplace.com/post/2021-04-13-%EB%B2%84%ED%82%B7%ED%94%8C%EB%A0%88%EC%9D%B4%EC%8A%A4-airflow-%EB%8F%84%EC%9E%85%EA%B8%B0/)
- [ë¼ì¸ ì—”ì§€ë‹ˆì–´ë§ Airflow on Kubernetes](https://engineering.linecorp.com/ko/blog/data-engineering-with-airflow-k8s-1)
- [Day1, 2-2. ê·¸ëŸ° REST APIë¡œ ê´œì°®ì€ê°€](https://www.youtube.com/watch?v=RP_f5dMoHFc)
- [HTTP response status codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Advanced User Guide for FastAPI](https://fastapi.tiangolo.com/advanced/)
- [Awesome-fastapi](https://github.com/mjhea0/awesome-fastapi)
- [ë„ì»¤(Docker) ì…ë¬¸í¸: ì»¨í…Œì´ë„ˆ ê¸°ì´ˆë¶€í„° ì„œë²„ ë°°í¬ê¹Œì§€](https://www.44bits.io/ko/post/easy-deploy-with-docker)
- [GCP ê³µì‹ ë¬¸ì„œ](https://cloud.google.com/docs?_gl=1*1qvbnv0*_up*MQ..&gclid=CjwKCAiA9bq6BhAKEiwAH6bqoH2F6QSWY2FuBmbvo00dn9Q17vhlVZWt-IHvBB4JCmDoHUTjymDqQhoCnygQAvD_BwE&gclsrc=aw.ds&hl=ko)
- [AWSë¥¼ ì´ìš©í•œ MLOps êµ¬ì¶• ì‚¬ë¡€ ì‚´í´ë³´ê¸°](https://aws.amazon.com/ko/blogs/tech/aws-mlops-use-case/)
- [MLOps Principles - Automation](https://ml-ops.org/content/mlops-principles#automation)
- [Experiments Tracking](https://ml-ops.org/content/mlops-principles#reproducibility)
- [Reproducibility](https://ml-ops.org/content/mlops-principles#reproducibility)
- [Data Engineer Jobs](https://www.linkedin.com/jobs/data-engineer-jobs/)

## 6.7 ìµœì í™”/ê²½ëŸ‰í™”
- [ Softmax Temperature](https://medium.com/@harshit158/softmax-temperature-5492e4007f71)
- [Lecture 10 - Knowledge Distillation | MIT 6.S965](https://www.youtube.com/watch?v=tT9Lnt6stwA)
- [ A brief overview of Imitation Learning](https://smartlabai.medium.com/a-brief-overview-of-imitation-learning-8a8a75c44a9c)
- [Dynamic Quantization](https://pytorch.org/tutorials/recipes/recipes/dynamic_quantization.html)
- [ë”¥ëŸ¬ë‹ì˜ Quantization (ì–‘ìí™”)ì™€ Quantization Aware Training:](https://gaussian37.github.io/dl-concept-quantization/#qat-quantization-aware-training-%EB%B0%A9%EB%B2%95-1)
- [Transfer Learning for Computer Vision Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [Brief Overview of Parallelism Strategies](https://afmck.in/posts/2023-02-26-parallelism/)
- [Data Parallelism on CNN:](https://siboehm.com/articles/22/data-parallel-training)
- [Pipeline Parallelism Algorithm](https://siboehm.com/articles/22/pipeline-parallel-training)
- [ë‹¨ì¼ ë¨¸ì‹ ì„ ì‚¬ìš©í•œ ëª¨ë¸ ë³‘ë ¬í™” ëª¨ë²” ì‚¬ë¡€](https://tutorials.pytorch.kr/intermediate/model_parallel_tutorial.html)

# 7. ğŸ“ŒContribution í•˜ëŠ” ë°©ë²•

## 7.1 Forkë¥¼ í•œë‹¤.
- ì›ë³¸ ì €ì¥ì†Œë¥¼ ë‚´ ê³„ì •ìœ¼ë¡œ ë³µì‚¬(Fork)

## 7.2 PRë¥¼ ë³´ë‚¸ë‹¤.
- Forkí•œ ì €ì¥ì†Œì—ì„œ ë³€ê²½ ë‚´ìš©ì„ ì‘ì—…í•œ ë’¤ Pull Request(Pull Request)ë¥¼ ìƒì„±

## 7.3 Approveë¥¼ ë°›ìœ¼ë©´ Merge!
- ë¦¬ë·° í›„ ìŠ¹ì¸ì„ ë°›ìœ¼ë©´ ì›ë³¸ ì €ì¥ì†Œì— ë³€ê²½ì‚¬í•­ì´ ë³‘í•©(Merge)

>ì´ ë¬¸ì„œëŠ” ê³„ì† ì—…ë°ì´íŠ¸ ì˜ˆì •ì…ë‹ˆë‹¤.
ê¶ê¸ˆí•œ ì‚¬í•­ì´ë‚˜ ì œì•ˆì´ ìˆë‹¤ë©´ Issue í˜¹ì€ Pull Requestë¡œ ì•Œë ¤ì£¼ì„¸ìš”!
ê°ì‚¬í•©ë‹ˆë‹¤.
