# NaverAIBoostCamp_7ê¸°_paper

[![Since](https://img.shields.io/badge/since-2025.01.01-333333.svg?style=flat-square)](https://github.com/2JAE22/AI_Tech-paper)
[![author](https://img.shields.io/badge/author-2JAE22-0066FF.svg?style=flat-square)](https://github.com/2JAE22)
[![LICENSE](https://img.shields.io/github/license/2JAE22/AI_Tech-paper.svg?style=flat-square)](https://github.com/2JAE22/AI_Tech-paper/blob/main/LICENSE)
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2F2JAE22%2FAI_Tech-paper%2Fhit-counter&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)
[![All Contributors](https://img.shields.io/badge/all_contributors-2?style=flat-square)](https://github.com/2JAE22/AI_Tech-paper/graphs/contributors)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-FF66FF.svg?style=flat-square)](http://makeapullrequest.com)

[![Watch on GitHub](https://img.shields.io/github/watchers/2JAE22/AI_Tech-paper.svg?style=social)](https://github.com/2JAE22/AI_Tech-paper/watchers)
[![Star on GitHub](https://img.shields.io/github/stars/2JAE22/AI_Tech-paper.svg?style=social)](https://github.com/2JAE22/AI_Tech-paper/stargazers)
[![Fork on GitHub](https://img.shields.io/github/forks/2JAE22/AI_Tech-paper.svg?style=social)](https://github.com/2JAE22/AI_Tech-paper/network/members)
<br>

<br>

### ğŸš€ NaverAIBoostCamp ë…¼ë¬¸ ë° further readingëª¨ìŒ ğŸ“–

<br> 

<br> 

**Collaborator**

[<img src="https://avatars.githubusercontent.com/u/87936538?v=4" width="100">](https://github.com/2JAE22)  
[GitHub](https://github.com/2JAE22)

<br>

**Commit convention rule** : ë‚ ì§œ-[ì£¼ì œ]-ë‚´ìš©-ìƒíƒœ

`ex) 2025-01-04 [CV Recent Trends] All/Only_Paper/Only_Further Add/Update/Delete`

<br>

ì˜ëª»ëœ ë‚´ìš©ì€ [ì´ìŠˆ](https://github.com/2JAE22/AI_Tech-paper/issues)ì™€ [PR](https://github.com/2JAE22/AI_Tech-paper/pulls)ë¡œ ì•Œë ¤ì£¼ì„¸ìš” ğŸ’¡

<br>



<center>ğŸ™ë„ì›€ì„ ì£¼ì‹  ë¶„ë“¤ğŸ™</center>

<br>
<br>

<a href="https://github.com/2JAE22/AI_Tech-paper/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=2JAE22/AI_Tech-paper" />
</a>

<br>


#### ë” ì¢‹ì€ ì»¨í…ì¸ ë¥¼ ì œê³µë°›ê¸¸ ì›í•œë‹¤ë©´ [ğŸ’–í›„ì›í•˜ê¸°!!ğŸ’](https://github.com/sponsors/2JAE22)

# 1. ğŸ“ŒIntroduction
NaverAIboostCampì—ì„œ ì†Œê°œí•œ ë…¼ë¬¸ë“¤ì„ ì£¼ì œë³„ë¡œ ì •ë¦¬í•œ í´ë”ì…ë‹ˆë‹¤.
í˜„ì¬ëŠ” CV(Computer Vision) íŠ¸ë™ì˜ ë…¼ë¬¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•˜ê³  ìˆìœ¼ë©°, ì¶”í›„ ëª¨ë“  íŠ¸ë™ìœ¼ë¡œ í™•ì¥í•  ì˜ˆì •ì…ë‹ˆë‹¤.

# 2ì—ì„œ 5ê¹Œì§€ëŠ” ë…¼ë¬¸ë§Œ ìˆìŠµë‹ˆë‹¤.
- [6](#6-further-readingì—-ìˆì—ˆë˜-ê²ƒë“¤)ë¶€í„° ë…¼ë¬¸ì™¸ì˜ ì‚¬ì´íŠ¸ë“¤ì„ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.

# 2. ğŸ“ŒCV íŠ¸ë™ ì •ë¦¬(Only Paper)
## 2.1 CV ì´ë¡ 
- [VGGNet](https://arxiv.org/abs/1409.1556)  
- [ResNet](https://arxiv.org/abs/1512.03385)  
- [ViT](https://arxiv.org/abs/2010.11929)
- [Grad-CAM](https://arxiv.org/abs/1610.02391)
- [mixup](https://arxiv.org/abs/1710.09412)
- [CutMix](https://arxiv.org/abs/1905.04899)
- [Fully Convolutional Networks for Semantic Segmentation](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)
- [SAM](https://arxiv.org/pdf/2304.02643)
- [DETR](https://arxiv.org/pdf/2005.12872)
- [Real-World Single Image Super-Resolution: A New Benchmark and A New Model](https://arxiv.org/abs/1904.00523)
- [Real-World Blur Dataset for Learning and Benchmarking Deblurring Algorithms](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123700188.pdf)
- [Blind Super-Resolution Kernel Estimation using an Internal-GAN](https://arxiv.org/abs/1909.06581)
- [SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://arxiv.org/abs/2404.04319)
- [CLIP huggingface implementation](https://github.com/huggingface/transformers/blob/main/src/transformers/models/clip/modeling_clip.py)
- [ImageBIND official implementation](https://github.com/facebookresearch/ImageBind)
- [LanguageBIND](https://arxiv.org/abs/2310.01852)
- [Flamingo pytorch implementation](https://github.com/lucidrains/flamingo-pytorch/blob/main/flamingo_pytorch/flamingo_pytorch.py)
- [LLaVA](https://llava-vl.github.io/)
- [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/abs/2201.12086)
- [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)
- [DDPM](https://arxiv.org/abs/2006.11239)
- [LDM (Stable Diffusion)](https://arxiv.org/abs/2112.10752)
- [DDIM](https://arxiv.org/abs/2010.02502) 
- [3D MACHINE LEARNING](https://www.antoinetlc.com/blog-summary/3d-data-representations)
- [Mesh R-CNN](https://arxiv.org/abs/1906.02739)
- [NeRF](https://arxiv.org/abs/2003.08934)
- [3DGS](https://arxiv.org/abs/2308.04079)
- [DreamFusion](https://arxiv.org/abs/2209.14988)
- [Loper et al., SMPL: A Skinned Multi-Person Linear Model: SIGGRAPH 2015.](https://dl.acm.org/doi/10.1145/2816795.2818013)
- [Bogo et al., Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image: ECCV 2016.](https://arxiv.org/abs/1607.08128)
- [Anguelov et al., SCAPE: Shape Completion and Animation of People: SIGGRAPH 2005.](https://dl.acm.org/doi/10.1145/1073204.1073207)


## 2.2 CV ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [A survey on Image Data Augmentation for Deep Learning](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)
- [AutoAugment: Learning Augmentation Strategies from Data](https://arxiv.org/abs/1805.09501)
- [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/abs/1909.13719)
- [Fine-Grained Image Analysis with Deep Learning: A Survey](https://arxiv.org/abs/2111.06119)
- [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
- [CoAtNet: Marrying Convolution and Attention for All Data Sizes](https://arxiv.org/abs/2106.04803)
- [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases](https://arxiv.org/abs/2103.10697)
- [Multimodal Learning with Transformers: A Survey](https://arxiv.org/abs/2206.06488)
- [Self-supervised Learning: Generative or Contrastive](https://arxiv.org/abs/2006.08218)
- [Ensemble deep learning: A review](https://arxiv.org/abs/2104.02395)
  
## 2.3 Object Detection
- [R-CNN](https://arxiv.org/abs/1311.2524)
- [Fast R-CNN](https://arxiv.org/abs/1504.08083)
- [Faster R-CNN](https://arxiv.org/abs/1506.01497)
- [SPPNet](https://arxiv.org/abs/1406.4729)
- [FPN](https://arxiv.org/abs/1612.03144)
- [PAFPN](https://arxiv.org/abs/1803.01534)
- [DetectoRS](https://arxiv.org/abs/2006.02334)
- [EfficientDet (BiFPN)](https://arxiv.org/abs/1911.09070v7)
- [NasFPN](https://arxiv.org/abs/1904.07392)
- [AugFPN](https://arxiv.org/abs/1912.05384)
- [YOLO survey](https://arxiv.org/abs/2304.00501)
- [Retinanet (focal loss)](https://arxiv.org/abs/1708.02002)
- [SSD](https://arxiv.org/abs/1512.02325)
- [EfficientNet](https://arxiv.org/abs/1905.11946)
- [EfficientDet](https://arxiv.org/abs/1911.09070)
- [DCN](https://arxiv.org/abs/1703.06211)
- [DETR](https://arxiv.org/abs/2005.12872)
- [Swin](https://arxiv.org/abs/2103.14030)
- [YOLO v4](https://arxiv.org/abs/2004.10934)
- [M2Det](https://arxiv.org/abs/1811.04533)
- [CornerNet](https://arxiv.org/abs/1808.01244)

## 2.4 Data-Centric AI
- [DMLR](https://openreview.net/pdf?id=2kpu78QdeE)
- [Convolutional Character Networks](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xing_Convolutional_Character_Networks_ICCV_2019_paper.pdf)
- [EAST](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_EAST_An_Efficient_CVPR_2017_paper.pdf)
- [Data and its (dis)contents: A survey of dataset development and use in machine learning research](https://www.sciencedirect.com/science/article/pii/S2666389921001847)
- [Human-In-The-Loopì— ëŒ€í•œ survey ë…¼ë¬¸](https://www.sciencedirect.com/science/article/abs/pii/S0167739X22001790?casa_token=5poWCKizHjIAAAAA:Z8eK3GMWCCwOncUmdz2J8JHGNYAx3N4MW_31Uq3CnWVQN2C6RXXtOqc50GveYglcudc9TiwhYKk)
- [ë‹¤ì–‘í•œ taskì— ì ìš© ê°€ëŠ¥í•œ IAAì— ê´€í•œ ë…¼ë¬¸](https://dl.acm.org/doi/10.1145/3485447.3512242)
- [LLMì„ í™œìš©í•œ data annotationì— ê´€í•œ survey ë…¼ë¬¸](https://arxiv.org/abs/2402.13446)
- [A survey on Image Data Augmentation for Deep Learning](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)
- [A survey of synthetic data augmentation methods in computer vision](https://arxiv.org/abs/2403.10075)



## 2.5 Semantic Segmentation
- [FCN](https://arxiv.org/abs/1411.4038)
- [DeconvNet](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.pdf)
- [SegNet](https://arxiv.org/pdf/1511.00561)
- [FCDenseNet](https://arxiv.org/pdf/1611.09326)
- [Unet](https://arxiv.org/abs/1505.04597)
- [DeepLabv1](https://arxiv.org/pdf/1412.7062)
- [DilatedNet ](https://arxiv.org/abs/1511.07122)
- [DeepLabv2](https://arxiv.org/pdf/1606.00915)
- [PSPNet](https://arxiv.org/pdf/1612.01105)
- [DeepLabv3](https://arxiv.org/pdf/1706.05587)
- [DeepLabv3+](https://arxiv.org/pdf/1802.02611)
- [Unet](https://arxiv.org/abs/1505.04597)
- [Unet++](https://arxiv.org/pdf/1912.05074)
- [Unet3+](https://arxiv.org/abs/2004.08790)
- [EfficientUnet](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w22/Baheti_Eff-UNet_A_Novel_Architecture_for_Semantic_Segmentation_in_Unstructured_Environment_CVPRW_2020_paper.pdf)
- [DenseUnet](https://arxiv.org/abs/1611.09326)
- [ResidualUnet](https://arxiv.org/pdf/1711.10684)
- [SWA](https://arxiv.org/abs/1803.05407)
- [HRNet](https://arxiv.org/pdf/1908.07919)
- [SegFormer](https://arxiv.org/pdf/2105.15203)
- [ViT](https://arxiv.org/pdf/2010.11929)
- [Weakly Supervised Object Localization and Detection: A Survey](https://arxiv.org/abs/2104.07918)

## 2.6 CV Recent Trends
- [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)
- [Variational Diffusion Models](https://arxiv.org/abs/2107.00630)
- [NVAE: A Deep Hierarchical Variational Autoencoder](https://arxiv.org/abs/2007.03898)
- [Denoising Diffusion Probabilistic Model](https://arxiv.org/abs/2006.11239)
- [Improved Denoising Diffusion Probabilistic Model](https://arxiv.org/abs/2102.09672)
- [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)
- [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502)
- [Progressive Distillation for Fast Sampling of Diffusion Models](https://arxiv.org/abs/2202.00512)
- [Consistency Models](https://arxiv.org/abs/2303.01469)
- [Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233)
- [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)
- [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](https://arxiv.org/abs/2205.11487)
- [Hierarchical Text-Conditional Image Generation with CLIP latents](https://arxiv.org/abs/2204.06125)
- [SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations](https://arxiv.org/abs/2108.01073)
- [Dual Diffusion Implicit Bridges for Image-to-Image Translation](https://arxiv.org/abs/2203.08382)
- [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543)
- [An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion](https://arxiv.org/abs/2208.01618)
- [Dreambooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://arxiv.org/abs/2208.12242)
- [Erasing Concepts from Diffusion Models](https://arxiv.org/abs/2303.07345)
- [Unified Concept Editing in Diffusion Models](https://arxiv.org/abs/2308.14761)
- [Video Diffusion Models](https://arxiv.org/abs/2204.03458)
- [Video Probabilistic Diffusion Models in Projected Latent Space](https://arxiv.org/abs/2302.07685)
- [Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2304.08818)
- [DreamFusion: Text-to-3D using 2D Diffusion](https://arxiv.org/abs/2209.14988)
- [zero-1-to-3: zero-shot one image to 3d object](https://arxiv.org/abs/2303.11328)
- [Consistent-1-to-3: Consistent Image to 3D View Synthesis via Geometry-aware Diffusion Models](https://arxiv.org/abs/2310.03020)
- [Cascaded Diffusion Models for High Fidelity Image Generation](https://arxiv.org/abs/2106.15282)
- [DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior](https://arxiv.org/abs/2308.15070)
- [Solving Inverse Problem in Medical Imaging with Score-Based Generative Models](https://arxiv.org/abs/2111.08005)
- [Label-Efficient Semantic Segmentation with Diffusion Models](https://arxiv.org/abs/2112.03126)
- [ODISE: Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models](https://arxiv.org/abs/2303.04803)
- [Your Diffusion Model is secretly a zero-shot classifier](https://arxiv.org/abs/2303.16203)
- [Emergent Correspondence from Image Diffusion](https://arxiv.org/abs/2306.03881)
- [AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise](https://ieeexplore.ieee.org/document/9857019)


# 3. ğŸ“ŒNLP íŠ¸ë™ ì •ë¦¬(Only Paper)
## 3.1 NLP ì´ë¡ 
- [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)
- [GloVe: Global Vectors for Word Representation](https://aclanthology.org/D14-1162/)
- [LSTM](https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext)
- [Highway Networks](https://arxiv.org/abs/1505.00387)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)
- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
- [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)
- [Sparse is Enough in Scaling Transformers](https://openreview.net/pdf?id=-b5OSCydOMe)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Layer Normalization](https://arxiv.org/abs/1607.06450)
- [Group Normalization](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yuxin_Wu_Group_Normalization_ECCV_2018_paper.pdf)
- [Attention is not Explanation](https://arxiv.org/pdf/1902.10186)
- [Attention is not not Explanation](https://aclanthology.org/D19-1002.pdf)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)
- [Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/abs/1609.08144)
- [Neural Network Acceptability Judgments](https://arxiv.org/abs/1805.12471)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](https://arxiv.org/abs/1704.05426)
- [SQuAD: 100,000+ Questions for Machine Comprehension of Text](https://arxiv.org/abs/1606.05250)
- [Hierarchical Neural Story Generation](https://arxiv.org/abs/1805.04833)
- [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)

  
## 3.2 NLP ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Quantifying Attention Flow in Transformers](https://arxiv.org/abs/2005.00928)
- [LoRA](https://arxiv.org/abs/2106.09685)
- [Non-Autoregressive & Autoregressive](https://arxiv.org/abs/2102.08220)


## 3.3 MRC(Machine Reading Comprehension)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://www.boostcourse.org/boostcampaitech7/lecture/1545463?isDesc=false)
- [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)
- [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5) ](https://arxiv.org/abs/1910.10683)
- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906)
- [Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/abs/1704.00051)
- [A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and Benchmark Datasets](https://arxiv.org/abs/2006.11880)
- [Latent Retrieval for Weakly Supervised Open Domain Question Answering](https://arxiv.org/abs/1906.00300)
- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906)
- [Exploring the limits of transfer learning with a unified text-to-text transformer(T5)](https://arxiv.org/abs/1910.10683)
- [How much knowledge can you pack into the parameters of language model?](https://arxiv.org/abs/2002.08910)
- [UNIFIEDQA: Crossing Format Boundaries with a Single QA System](https://arxiv.org/abs/2005.00700)
- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
- [Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index](https://arxiv.org/abs/1906.05807)
- [Contextualized Sparse Representations for Real-Time Open-Domain Question Answering](https://arxiv.org/abs/1911.02896)


## 3.4 Data-Centric NLP
- [DMOps: Data Management Operation and Recipes](https://arxiv.org/abs/2301.01228)
- [A Survey on Awesome Korean NLP Datasets](https://ieeexplore.ieee.org/abstract/document/9952930)
- [ProsocialDialog: A Prosocial Backbone for Conversational Agents](https://aclanthology.org/2022.emnlp-main.267/)
- [Natural Language Processing: State of The Art, Current Trends and Challenges](https://arxiv.org/abs/1708.05148)
- [Understanding Back-Translation at Scale](https://arxiv.org/abs/1808.09381)
- [EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks](https://arxiv.org/abs/1901.11196)
- [Data Augmentation using Pre-trained Transformer Models](https://arxiv.org/abs/2003.02245)
- [AugGPT: Leveraging ChatGPT for Text Data Augmentation](https://arxiv.org/abs/2302.13007)
- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/abs/2107.13586)
- [Everyone's Voice Matters: Quantifying Annotation Disagreement Using Demographic Information](https://arxiv.org/abs/2301.05036)
- [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)
- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)


## 3.5 Generative for NLP
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()

## 3.6 NLP Recent Trends
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()


# 4. ğŸ“ŒRecsys íŠ¸ë™ ì •ë¦¬(Only Paper)
## 4.1 Recsys ì´ë¡ 
- [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)
- [Diffusion Recommendation Model](https://arxiv.org/abs/2304.04971)
- [Bayesian Probabilistic Matrix Factorization using Markov Chain Monte Carlo](https://www.cs.cmu.edu/~rsalakhu/papers/bpmf.pdf)
- [Probabilistic Matrix Factorization](https://proceedings.neurips.cc/paper_files/paper/2007/file/d7322ed717dedf1eb4e6e52a37ea7bcd-Paper.pdf)
- [Understanding Black-box Predictions via Influence Functions, ICML 2017](https://arxiv.org/pdf/1703.04730)
- [Data Shapley: Equitable Valuation of Data for Machine Learning,ICML 2019](https://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf)
- [Data Valuation using Reinforcement Learning, ICML 2020](https://proceedings.mlr.press/v119/yoon20a/yoon20a.pdf)
- [Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value, ICML 2023](https://arxiv.org/pdf/2304.07718)
- [Efficient Neural Causal Discovery without Acyclicity Constraints](https://arxiv.org/abs/2107.10483)
- [A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms ](https://arxiv.org/abs/1901.10912)
- [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality](https://arxiv.org/abs/2305.00050)


## 4.2 ML ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [A Brief Introduction to Machine Learning for Engineers](https://arxiv.org/abs/1709.02840)
- [Zheng, Alice, and Amanda Casari. Feature engineering for machine learning: principles and techniques for data scientists. " O'Reilly Media, Inc.", 2018.](https://books.google.co.kr/books?hl=ko&lr=&id=sthSDwAAQBAJ&oi=fnd&pg=PT14&dq=Zheng,+Alice,+and+Amanda+Casari.+Feature+engineering+for+machine+learning:+principles+and+techniques+for+data+scientists.+%22+O%27Reilly+Media,+Inc.%22,+2018.&ots=ZPZfvU0jz-&sig=tjYsynIo-QTjNiZuFPOuuHB6naY#v=onepage&q=Zheng%2C%20Alice%2C%20and%20Amanda%20Casari.%20Feature%20engineering%20for%20machine%20learning%3A%20principles%20and%20techniques%20for%20data%20scientists.%20%22%20O'Reilly%20Media%2C%20Inc.%22%2C%202018.&f=false)
- [Hastie, Trevor, et al. The elements of statistical learning: data mining, inference, and prediction. Vol. 2. New York: springer, 2009.](https://link.springer.com/book/10.1007/978-0-387-21606-5)
- [SMOTE: synthetic minority over-sampling technique. Journal of artificial intelligence research, 16, 321-357.](https://arxiv.org/abs/1106.1813)
- [Gradient Boosting Paper](https://www.semanticscholar.org/paper/Greedy-function-approximation%3A-A-gradient-boosting-Friedman/1679beddda3a183714d380e944fe6bf586c083cd)
- [XGBoost Paper](https://www.semanticscholar.org/paper/XGBoost%3A-A-Scalable-Tree-Boosting-System-Chen-Guestrin/26bc9195c6343e4d7f434dd65b4ad67efe2be27a)
- [LightGBM Paper](https://www.semanticscholar.org/paper/LightGBM%3A-A-Highly-Efficient-Gradient-Boosting-Tree-Ke-Meng/497e4b08279d69513e4d2313a7fd9a55dfb73273)
- [Lasso Regression Paper](https://webdoc.agsci.colostate.edu/koontz/arec-econ535/papers/Tibshirani%20(JRSS-B%201996).pdf)
- [Ridge Regression Paper](https://mineracaodedados.wordpress.com/wp-content/uploads/2015/06/ridge-regression-biased-estimation-for-nonorthogonal-problems.pdf)
- [Ensemble deep learning: A review](https://arxiv.org/abs/2104.02395)
- [Random Search for Hyper-Parameter Optimization](https://www.jmlr.org/papers/v13/bergstra12a.html)
- [Practical Bayesian Optimization of Machine Learning Algorithms](https://arxiv.org/abs/1206.2944)
- [Hyperparameters and Tuning Strategies for Random Forest](https://arxiv.org/abs/1804.03515)
- [Management of Machine Learning Lifecycle Artifacts: A Survey](https://arxiv.org/abs/2210.11831)


## 4.3 Competitive DS
- [ArcFace: Additive Angular Margin Loss for Deep Face Recognition](https://arxiv.org/abs/1801.07698)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [LONG SHORT-TERM MEMORY](https://www.bioinf.jku.at/publications/older/2604.pdf)
- [SAINT Model Paper](https://arxiv.org/abs/2108.12775)
- [Deep Knowledge Tracing](https://arxiv.org/abs/1506.05908)


## 4.4 RecSys ê¸°ì´ˆí”„ë¡œì íŠ¸
- [Improved Apriori Algorithm for Mining Association Rules](https://www.mecs-press.org/ijitcs/ijitcs-v6-n7/IJITCS-V6-N7-3.pdf)
- [Matrix Factorization Techniques for Recommender Systems ](https://datajobs.com/data-science-repo/Recommender-Systems-%5bNetflix%5d.pdf)
- [BPR: Bayesian personalized ranking from implicit feedback](https://arxiv.org/pdf/1205.2618)
- [Neural Collaborative Filtering](https://arxiv.org/pdf/1708.05031)
- [Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/45530.pdf)
- [AutoRec: Autoencoders Meet Collaborative Filtering](https://users.cecs.anu.edu.au/%7Eakmenon/papers/autorec/autorec-paper.pdf)
- [Collaborative Denoising Auto-Encoders for Top-N Recommender Systems](https://www.datascienceassn.org/sites/default/files/Collaborative%20Denoising%20Auto-Encoders%20for%20Top-N%20Recommender%20Systems.pdf)
- [Neural Graph Collaborative Filtering](https://arxiv.org/pdf/1905.08108)
- [LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation](https://arxiv.org/pdf/2002.02126)
- [When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation](https://web-ainf.aau.at/pub/jannach/files/Conference_RecSys_2017.pdf)
- [Factorization Machines](https://sdcast.ksdaemon.ru/wp-content/uploads/2020/02/Rendle2010FM.pdf)
- [Field-aware Factorization Machines for CTR Prediction](https://www.csie.ntu.edu.tw/%7Ecjlin/papers/ffm.pdf)
- [Greedy Function Approximation: A Gradient Boosting Machine](https://jerryfriedman.su.domains/ftp/trebst.pdf)
- [XGBoost: A Scalable Tree Boosting System](https://dl.acm.org/doi/pdf/10.1145/2939672.2939785)
- [LightGBM: A Highly Efficient Gradient Boosting Decision Tree](https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)
- [CatBoost: unbiased boosting with categorical features](https://arxiv.org/pdf/1706.09516)
- [Wide & Deep Learning for Recommender Systems](https://dl.acm.org/doi/pdf/10.1145/2988450.2988454)
- [DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](https://arxiv.org/pdf/1703.04247)
- [Deep Interest Network for Click-Through Rate Prediction](https://arxiv.org/pdf/1706.06978)
- [Behavior Sequence Transformer for E-commerce Recommendation in Alibaba](https://arxiv.org/pdf/1905.06874)
- [An Empirical Evaluation of Thompson Sampling](https://proceedings.neurips.cc/paper/2011/file/e53a0a2978c28872a4505bdb51db06dc-Paper.pdf)
- [A Contextual-Bandit Approach to Personalized News Article Recommendation](https://arxiv.org/pdf/1003.0146)
- [RecSys Challenge 2023: Deep Funnel Optimization with a Focus on User Privacy](https://dl.acm.org/doi/proceedings/10.1145/3626221)

## 4.5 Movie Rec
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()

## 4.6 Recsys Recent Trends
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
# 5. ğŸ“Œê³µí†µ ê°•ì˜ì—ì„œ ì†Œê°œí•œ ë…¼ë¬¸ ì •ë¦¬
## 5.1 Generative AI
- [LLM Survey ë…¼ë¬¸ (2023)](https://arxiv.org/abs/2303.18223)
- [GAN Survey ë…¼ë¬¸ (2020)](https://arxiv.org/abs/1906.01529)
- [Diffusion Models Survey ë…¼ë¬¸ (2024)](https://arxiv.org/abs/2209.00796)
- [RLHF ì œì•ˆ ë…¼ë¬¸](https://arxiv.org/abs/2203.02155)
- [Large Language Model ì„œë² ì´ ë…¼ë¬¸](https://arxiv.org/abs/2303.18223)
- [GPT-3 ë…¼ë¬¸](https://arxiv.org/abs/2005.14165)
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
- [Self-Instruct ë…¼ë¬¸](https://arxiv.org/abs/2212.10560)
- [Self-Rewarding ë…¼ë¬¸](https://arxiv.org/pdf/2401.10020)
- [GAN ë…¼ë¬¸](https://arxiv.org/abs/1406.2661)
- [cGAN ë…¼ë¬¸](https://arxiv.org/abs/1411.1784)
- [Pix2Pix ë…¼ë¬¸](https://arxiv.org/abs/1611.07004)
- [CycleGAN ë…¼ë¬¸](https://arxiv.org/abs/1703.10593)
- [StarGAN ë…¼ë¬¸](https://arxiv.org/abs/1711.09020)
- [ProgressiveGAN ë…¼ë¬¸](https://arxiv.org/abs/1710.10196)
- [StyleGAN ë…¼ë¬¸](https://arxiv.org/abs/1812.04948)
- [VAE ë…¼ë¬¸](https://arxiv.org/abs/1312.6114)
- [VQ-VAE ë…¼ë¬¸](https://arxiv.org/abs/1711.00937)
- [DDPM ë…¼ë¬¸](https://arxiv.org/abs/2006.11239)
- [DDIM ë…¼ë¬¸](https://arxiv.org/abs/2010.02502)
- [Classifier Guidance ë…¼ë¬¸](https://arxiv.org/abs/2105.05233)
- [Classifier-free Guidance ë…¼ë¬¸](https://arxiv.org/abs/2207.12598)
- [LDM ë…¼ë¬¸](https://arxiv.org/abs/2112.10752)
- [Latent Diffusion Model](https://arxiv.org/abs/2112.10752)
- [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)
- [SDXL Turbo (Adversarial Diffusion Distillation)](https://arxiv.org/abs/2311.17042)




## 5.2 Product Serving
- paper ì—†ìŒ


## 5.3 ìµœì í™”/ê²½ëŸ‰í™”
- [Rethinking the Value of Network Pruning](https://arxiv.org/abs/1810.05270)
- [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](https://arxiv.org/abs/1712.05877)
- [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks:](https://arxiv.org/abs/1803.03635)
- [Pruning Convolutional Neural Networks for Resource Efficient Inference](https://arxiv.org/abs/1611.06440)
- [Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning](https://arxiv.org/abs/2002.08307)
- [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)
- [Parameter-Efficient Transfer Learning for NLP ](https://arxiv.org/pdf/1902.00751)
- [Prompt tuning ](https://arxiv.org/pdf/2104.08691)
- [Prefix tuning ](https://arxiv.org/pdf/2101.00190)
- [AdapterFusion: Non-Destructive Task Composition for Transfer Learning](https://arxiv.org/abs/2005.00247)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)

---

**ì—¬ê¸°ì„œë¶€í„°ëŠ” ë…¼ë¬¸ì™¸ì˜ ì½ì„ê±°ë¦¬ë“¤ë¡œ ìˆì—ˆë˜ ê²ƒë“¤ì„ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.**
# 6. ğŸ“ŒFurther Readingì— ìˆì—ˆë˜ ê²ƒë“¤.
## 6.1 ê³µí†µì½”ìŠ¤
### 6.1.1 Pytorch
- [Introduction to PyTorch â€” PyTorch Tutorials documentation](https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html)
- [í…ì„œ(Tensor) â€” íŒŒì´í† ì¹˜ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ (PyTorch tutorials in Korean)](https://tutorials.pytorch.kr/beginner/introyt/introyt1_tutorial.html)
- [torch.Tensor â€” PyTorch documentation](https://pytorch.org/docs/main/tensors.html)
- [ë¶€ë™ì†Œìˆ˜ì  - ë°±ê³¼ì‚¬ì „](https://ko.wikipedia.org/wiki/%EB%B6%80%EB%8F%99%EC%86%8C%EC%88%98%EC%A0%90)
- [torch.randn â€” PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn)
- [torch.Tensor â€” PyTorch documentation](https://pytorch.org/docs/main/tensors.html)
- [GPUì™€ AI - ë„¤ì´ë²„ ì§€ì‹ë°±ê³¼](https://terms.naver.com/entry.naver?docId=2080143&cid=50305&categoryId=50305)
- [torch.Tensor.view â€” PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.Tensor.view.html#torch-tensor-view)
- [torch.reshape â€” PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.reshape.html#torch-reshape)
- [Difference between view, reshape, transpose and permute in PyTorch](https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/)
- [torch.squeeze â€” PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.squeeze.html#torch-squeeze)
- [Tensor ëª¨ì–‘ ì„¤ëª…](https://velog.io/@jk01019/broadcastto-repeat-repeatinterleave-view-reshape-expand-expandas-tile-flatten-unsqueeze-squeeze-stack-cat-d1n8ersb)
- [$L_p$ norm](https://en.m.wikipedia.org/wiki/Lp_space)
- [ì„ í˜•íšŒê·€](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)
- [ê²½ì‚¬í•˜ê°•ë²• í•™ìŠµë°©ë²•](https://www.youtube.com/watch?v=IHZwWFHWa-w)
- [Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)
- [PyTorch DataLoader â€” PyTorch main documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)
- [BCELoss â€” PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)
- [BCEWithLogitsLoss â€” PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss)
- [CrossEntropyLoss â€” PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)

### 6.1.2 ML LifeCycle
- [A survey on Image Data Augmentation for Deep Learning ](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0) 
- [Clipping](https://arxiv.org/pdf/1211.5063) 
- [LSTM â€” PyTorch main documentation ](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) 
- [Attention Is All You Need ](https://arxiv.org/pdf/1706.03762) 
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding ](https://arxiv.org/pdf/1810.04805) 
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale ](https://arxiv.org/pdf/2010.11929) 


### 6.1.3 EDA & DataViz
- [[Harvard Business Review] Boost Your Team's Data Literacy](https://hbr.org/2020/02/boost-your-teams-data-literacy)
- [[Sequoia Capital] Why Data Science Matters](https://medium.com/sequoia-capital/why-data-science-matters-ee583f785a55)
- [[Sequoia Capital] Role of Data Scientist](https://medium.com/sequoia-capital/five-core-skills-of-a-data-scientist-fc044014fafa)
- [ë°ì´í„° ì‹œê°í™” êµê³¼ì„œ (í´ë¼ìš°ìŠ¤ ìœŒì¼€ ì €)](https://clauswilke.com/dataviz/index.html)
- [Data Viz Project](https://datavizproject.com/)
- [Misleading Data Visualization](https://pressbooks.library.torontomu.ca/criticaldataliteracy/chapter/misleading-data-visualizations/)
- [[The Economists] Mistakes, we've drawn a few](https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368)
- [[Google ML Course] Types of Bias](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias?hl=ko)
- [[Github] Awesome Feature Engineering](https://github.com/aikho/awesome-feature-engineering)
- [[ì„œìš¸ëŒ€ AI ì—°êµ¬ì›] ë‹¤ì°¨ì› ë°ì´í„° ì‹œê°í™”ì™€ AI (ì»´í“¨í„°ê³µí•™ë¶€ ì„œì§„ìš± êµìˆ˜)](https://www.youtube.com/watch?v=ymA1spEAd7M)
- [[Distill] How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)
- [Forecasting: Principles & Practice](https://otexts.com/fppkr/arima.html)
- [Hugging Face - NLP Course](https://huggingface.co/learn/nlp-course/ko/chapter1/2?fw=pt)
- [Text Visualization Browser](https://textvis.lnu.se/)
- [[Github] eugeneyan/applied-ml](https://github.com/eugeneyan/applied-ml)
- [[Material Design] Data Visualization](https://m2.material.io/design/communication/data-visualization.html)
- [ì˜ëª» ì‚¬ìš©ëœ ì‹œê°í™” ëª¨ìŒ WTF.viz](https://viz.wtf/)
- [Startup Metrics for Pirates: AARRR! - Dave McClure](https://www.youtube.com/watch?v=irjgfW0BIrw)
- [ë°ì´í„° ì‹œê°í™”, ì¸ì§€ê³¼í•™ì„ ë§Œë‚˜ë‹¤ ](https://www.yes24.com/Product/Goods/19013968)
- [ë„ë„ë“œ ë…¸ë§Œì˜ UX ë””ìì¸ íŠ¹ê°• ](https://www.yes24.com/Product/Goods/59673763)
- [UX/UIì˜ 10ê°€ì§€ ì‹¬ë¦¬í•™ ë²•ì¹™ ](https://product.kyobobook.co.kr/detail/S000212939982)

### 6.1.4 AI ê°œë°œ ê¸°ì´ˆ
- ["Clean Code: A Handbook of Agile Software Craftsmanship" by Robert C. Martin:](https://www.oreilly.com/library/view/clean-code-a/9780136083238/)
- ["Design Patterns: Elements of Reusable Object-Oriented Software" by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissidesn](https://www.oreilly.com/library/view/design-patterns-elements/0201633612/)
- ["ëª¨ë˜ ë¦¬ëˆ…ìŠ¤ êµê³¼ì„œ" by ë§ˆì´í´ í•˜ìš°ì„¼ë¸”ë¼ìŠ¤](https://product.kyobobook.co.kr/detail/S000210138053)
- ["The Linux Command Line" by William Shotts:](https://wiki.lib.sun.ac.za/images/c/ca/TLCL-13.07.pdf)
- [Streamlit ê³µì‹ ë¬¸ì„œ](https://docs.streamlit.io/)
- [Python 3.x Docs: Virtual Environments and Packages](https://docs.python.org/3/tutorial/venv.html)



## 6.2 CV
### 6.2.1 CV ì´ë¡    
- [í•œê²¨ë¡€ ë‰´ìŠ¤ "ë¹Œê²Œì´ì¸ ë„ ê°íƒ„í•œ ìµœì˜ˆì§„ êµìˆ˜, ìƒì„±í˜• AI í•™ìŠµ ë°ì´í„° ê³µê°œí•´ì•¼"](https://www.hani.co.kr/arti/economy/economy_general/1128825.html)




### 6.2.2 CV ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [Kaggle Competition](https://www.kaggle.com/competitions)
- [Image file format](https://en.wikipedia.org/wiki/Image_file_format)
- [Multilabel Image Classification Using Deep Learning](https://www.mathworks.com/help/deeplearning/ug/multilabel-image-classification-using-deep-learning.html)
- [Training with Pytorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)
- [Pytorch: Automatic Mixed Precision ](https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html)
- [Nvidia: Mixed-Precision-Training](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html)
- [Tensorboard](https://www.tensorflow.org/tensorboard/get_started?hl=ko)
- [WandB](https://wandb.ai/site/ko/)  

### 6.2.3 Object Detection
- [mmdetection github](https://github.com/open-mmlab/mmdetection)
- [detectron2 github](https://github.com/facebookresearch/detectron2)
- [Paperswithcode Object Detection](https://paperswithcode.com/task/object-detection)
- [Kaggle](https://www.kaggle.com/competitions)

### 6.2.4 Data-Centric AI
- [AI ìµœì‹  í™œìš© ì‚¬ë¡€](https://www.content.upstage.ai/blog/insight/examples-of-artificial-intelligence)
- [í˜„ì‹¤ ì„¸ê³„ì—ì„œì˜ ë°ì´í„°ì¤‘ì‹¬ AI](https://ko.upstage.ai/blog/tech/data-centric-ai-in-the-real-world)
- [SynthText in the Wild Dataset](https://www.robots.ox.ac.uk/~vgg/data/scenetext/)
- [Tesseract (Off-the-shelf OCR open source)](https://tesseract-ocr.github.io/)
- [Data annotationì— ëŒ€í•œ OpenCVì˜ blogpost](https://opencv.org/blog/data-annotation/)


### 6.2.5 Semantic Segmentation
- [Segmentation models library](https://github.com/qubvel/segmentation_models)

### 6.2.6 CV Recent Trends
- [Generative Modeling by Estimating Gradients of the Data Distribution](https://yang-song.net/blog/2021/score/)


## 6.3 NLP
### 6.3.1 NLP ì´ë¡ 
- [Byte-Pair Encoding tokenization](https://huggingface.co/learn/nlp-course/en/chapter6/5)
- [The Illustrated Word2vec](https://jalammar.github.io/illustrated-word2vec/)
- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- [cs231n Lecture 10: Recurrent Neural Networks](https://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)
- [The Exploding and Vanishing Gradients Problem in Time Series](https://medium.com/metaor-artificial-intelligence/the-exploding-and-vanishing-gradients-problem-in-time-series-6b87d558d22)
- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [BertViz: Visualize Attention in NLP Models](https://github.com/jessevig/bertviz)
- [Foundations of NLP Explained Visually: Beam Search, How It Works](https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24)
- [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate)

  
### 6.3.2 NLP ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [Improving Language Understanding by Generative Pre-Training](https://paperswithcode.com/paper/improving-language-understanding-by)
- [Tokenizer ì— ëŒ€í•´](https://huggingface.co/docs/tokenizers/index)
- [Hugging Face Tokenizer í™œìš©í•˜ê¸°](https://huggingface.co/docs/tokenizers/quicktour)
- [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary#summary-of-the-tokenizers)
- [Hugging Face Tutorial](https://huggingface.co/learn/nlp-course/chapter1/1)
- [Hugging Face ë¬¸ì„œ](https://huggingface.co/docs)
- [T-value ì™€ P-value](https://www.allmath.com/t-critical-value.php)
- [BertViz](https://github.com/jessevig/bertviz)
- [Tune Hyperparameters with Sweeps (wandb.ai)](https://docs.wandb.ai/guides/sweeps/)
- [PEFT (Hugging Face)](https://huggingface.co/PEFT)
- [Parameterì™€ Hyperparameterì˜ ì°¨ì´](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/)
- [Text classification (Hugging Face)](https://huggingface.co/docs/transformers/tasks/sequence_classification)
- [Image Embeddingê³¼ Triplet Loss ê°„ë‹¨ ì„¤ëª… (tistory.com)](https://computing-jhson.tistory.com/134)
- [k-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „ (wikipedia.org)](https://ko.wikipedia.org/wiki/K-ìµœê·¼ì ‘_ì´ì›ƒ_ì•Œê³ ë¦¬ì¦˜)
- [Embedding Distance | ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/string/embedding_distance/)
- [BertForSequenceClassification](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForSequenceClassification)
- [transformers/src/transformers/models/bert/modeling_bert.py at v4.34.1 Â· huggingface/transformers (github.com)](https://github.com/huggingface/transformers/blob/v4.34.1/src/transformers/models/bert/modeling_bert.py#L1519)
- [What is Summarization? - Hugging Face](https://huggingface.co/tasks/summarization)
- [BART](https://huggingface.co/docs/transformers/main/en/model_doc/bart#overview)
- [OpenAI GPT2](https://huggingface.co/docs/transformers/main/en/model_doc/gpt2#openai-gpt2)
- [Trainer(Hugging Face)](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#trainer)
- [WandB](https://wandb.ai/site/ko/)
- [Model Hub(Hugging Face)](https://huggingface.co/docs/hub/models-the-hub)
- [Model Card (Hugging Face)](https://huggingface.co/docs/huggingface_hub/main/ko/guides/model-cards)
- [Streamlit tutorial](https://docs.streamlit.io/get-started/tutorials/create-an-app)
- [Annotated Model Card Template (Hugging Face)](https://huggingface.co/docs/hub/model-card-annotated#annotated-model-card-template)




### 6.3.3 MRC(Machine Reading Comprehension)
- [ë¬¸ìì—´ typeì— ê´€ë ¨ëœ ì •ë¦¬ê¸€](https://kunststube.net/encoding/)
- [KorQuAD ë°ì´í„° ì†Œê°œ ìŠ¬ë¼ì´ë“œ](https://www.slideshare.net/slideshow/korquad-introduction/129498665)
- [Naver Engineering: KorQuAD ì†Œê°œ ë° MRC ì—°êµ¬ ì‚¬ë¡€ ì˜ìƒ](https://tv.naver.com/v/5564630)
- [SQuAD ë°ì´í„°ì…‹ ë‘˜ëŸ¬ë³´ê¸°](https://rajpurkar.github.io/SQuAD-explorer/)
- [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)
- [Huggingface datasets](https://huggingface.co/datasets)
- [Introducing BART](https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html)
- [Pyserini BM25 MSmarco documnet retrieval ì½”ë“œ](https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-doc.md)
- [Sklearn feature extractor](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)
- [Open domain QA tutorial: Dense retrieval](https://github.com/danqi/acl2020-openqa-tutorial/blob/master/slides/part5-dense-retriever-e2e-training.pdf)
- [FAISS blog](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)
- [FAISS github](https://github.com/facebookresearch/faiss)
- [FAISS tutorial](https://github.com/facebookresearch/faiss/tree/main/tutorial/python)
- [Getting started with Faiss](https://www.pinecone.io/learn/series/faiss/faiss-tutorial/)
- [ACL 2020 ODQA tutorial](https://slideslive.com/38931668/t8-opendomain-question-answering)
- [Phrase Retrieval and Beyond](https://princeton-nlp.github.io/phrase-retrieval-and-beyond/)

### 6.3.4 Data-Centric NLP
- [Week 35 - ëª¨ë¸ ì¤‘ì‹¬ì—ì„œ ë°ì´í„° ì¤‘ì‹¬ì˜ AI ê°œë°œë¡œ](https://jiho-ml.com/weekly-nlp-35/)
- [Crowdsourced Data Collection Benefits & Best Practices ['25]](https://research.aimultiple.com/crowdsourced-data/)
- [KLUE benchmark](https://klue-benchmark.com/)
- [EIGHTH CONFERENCE ON MACHINE TRANSLATION (WMT23)](https://www2.statmt.org/wmt23/)
- [Tokenizers_huggingface](https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt)
- [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary)
- [2023ë…„ 1ë¶„ê¸° ì¸ê³µì§€ëŠ¥(AI) ë° ìì—°ì–´ì²˜ë¦¬(NLP) ì£¼ìš” ë‰´ìŠ¤](https://www.letr.ai/ko/blog/story-230407)
- [LLMì— í™˜ê°ì´ ë°œìƒí•˜ëŠ” ì›ì¸ê³¼ í•´ê²° ë°©ì•ˆ](https://moon-walker.medium.com/llm%EC%97%90-halluciation-%ED%99%98%EA%B0%81-%EC%9D%B4-%EB%B0%9C%EC%83%9D%ED%95%98%EB%8A%94-%EC%9B%90%EC%9D%B8%EA%B3%BC-%ED%95%B4%EA%B2%B0%EB%B0%A9%EC%95%88-f18759f0a959)


### 6.3.5 Generative for NLP
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()

### 6.3.6 NLP Recent Trends
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
## 6.4 Recsys
### 6.4.1 Recsys ì´ë¡ 
- [ì¤‘ì‹¬ê·¹í•œì •ë¦¬, Central Limit Theorem](https://m.blog.naver.com/mykepzzang/220851280035)
- [ìµœëŒ€ìš°ë„ë²•(MLE)](https://angeloyeo.github.io/2020/07/17/MLE.html)
- [ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸(Gaussian Mixture Model)](https://untitledtblog.tistory.com/133)
- [KL divergence](https://angeloyeo.github.io/2020/10/27/KL_divergence.html)
- [VI(Variational Inference)](https://velog.io/@gibonki77/Inference-2)
- [Markov Chain Monte Carlo - ê³µëŒì´ì˜ ìˆ˜í•™ì •ë¦¬ ë…¸íŠ¸](https://angeloyeo.github.io/2020/09/17/MCMC.html)
- [Influence Functionì— ëŒ€í•œ ì´í•´](https://tootouch.github.io/IML/influential_instances/)
- [Trustworthy Machine Learning (Chapter 3 p.116-p.219)](https://arxiv.org/abs/2310.08215)
- [Pythonìœ¼ë¡œ í•˜ëŠ” ì¸ê³¼ì¶”ë¡  : ê°œë…ë¶€í„° ì‹¤ìŠµê¹Œì§€](https://github.com/CausalInferenceLab/Causal-Inference-with-Python)


### 6.4.2 ML ê¸°ì´ˆ í”„ë¡œì íŠ¸
- [Is there a rule-of-thumb for how to divide a dataset into training and validation sets? - stackoverflow](https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio)
- [Data Leakage in The ICML 2013 Whale Challenge](https://www.kaggle.com/competitions/the-icml-2013-whale-challenge-right-whale-redux/discussion/4865)
- [regression-metrics-for-mashine-learning](https://machinelearningmastery.com/regression-metrics-for-machine-learning/)
- [Cross-Validation-Techniques](https://medium.com/geekculture/cross-validation-techniques-33d389897878)
- [Weights & Biases ê³µì‹ íŠœí† ë¦¬ì–¼ ë¬¸ì„œ](https://docs.wandb.ai/tutorials/)
- [Weights & Biases ê³µì‹ ì˜ˆì œ ê¹ƒí—ˆë¸Œ ì €ì¥ì†Œ](https://github.com/wandb/examples)
- [The Kaggle Book: Data analysis and machine learning for competitive data science. Packt Publishing Ltd, 2022.](https://github.com/PacktPublishing/The-Kaggle-Book)

### 6.4.3 Competitive DS
- [An Introduction to Statistical Learning](https://www.statlearning.com)
- [Pattern Recognition and Machine Learning](https://link.springer.com/book/9780387310732)
- [Time Series Analysis: Forecasting and Control](https://www.wiley.com/en-us/Time+Series+Analysis%3A+Forecasting+and+Control%2C+5th+Edition-p-9781118675021)
- [The Elements of Statistical Learning](https://hastie.su.domains/ElemStatLearn/)
- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/index.html)
- [Deep Learning book](https://www.deeplearningbook.org/)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [Introduction to Data Mining](https://www.pearson.com/en-us/subject-catalog/p/introduction-to-data-mining/P200000003204/9780137506286)
- [XGBoost Documentation](https://xgboost.readthedocs.io/en/stable/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/en/stable/)
- [CatBoost Documentation](https://catboost.ai/docs/en/)
- [Deep Learning for Time Series Forecasting](https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/)
- [Feature Engineering and Selection: A Practical Approach for Predictive Models](https://www.amazon.com/Feature-Engineering-Selection-Practical-Predictive/dp/1138079227)
- [Data Science for Business](https://www.oreilly.com/library/view/data-science-for/9781449374273/)
- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
- [Ensemble Methods: Foundations and Algorithms](https://www.routledge.com/Ensemble-Methods-Foundations-and-Algorithms/Zhou/p/book/9781439830031)
- [Automated Machine Learning: Methods, Systems, Challenges](https://link.springer.com/book/10.1007/978-3-030-05318-5)
- [Hyperparameter Optimization: A Practical Guide](https://link.springer.com/chapter/10.1007/978-3-030-05318-5_3)
- [Optuna Documentation](https://optuna.readthedocs.io/en/stable/)

### 6.4.4 RecSys ê¸°ì´ˆí”„ë¡œì íŠ¸
- [[ì¶”ì²œ ì‹œìŠ¤í…œ] ì„±ëŠ¥ í‰ê°€ ë°©ë²• - Precision, Recall, NDCG, Hit Rate, MAE, RMSE](https://sungkee-book.tistory.com/11)
- [í•œêµ­ì–´ì™€ NLTK, Gensimì˜ ë§Œë‚¨ @ PyCon Korea 2015](https://www.lucypark.kr/docs/2015-pyconkr/#1)
- [17 types of similarity and dissimilarity measures used in data science.](https://towardsdatascience.com/17-types-of-similarity-and-dissimilarity-measures-used-in-data-science-3eb914d2681)
- [Word2Vec ê·¸ë¦¬ê³  ì¶”ì²œ ì‹œìŠ¤í…œì˜ Item2Vec](https://brunch.co.kr/@goodvc78/16)
- [TOROS N2 - lightweight approximate Nearest Neighbor library](https://www.slideshare.net/ifkakao/toros-n2-lightweight-approximate-nearest-neighbor-library-119540069)
- [ANN-Benchmarks](https://ann-benchmarks.com/index.html)
- [(ì˜ìƒ) XGBoost - StatQuest](https://www.youtube.com/playlist?list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ)
- [(ì˜ìƒ) 04-8: Ensemble Learning - LightGBM (ì•™ìƒë¸” ê¸°ë²• - LightGBM)](https://www.youtube.com/watch?v=4C8SUZJPlMY)
- [Catboost ì£¼ìš” ê°œë…ê³¼ íŠ¹ì§• ì´í•´í•˜ê¸°](https://dailyheumsi.tistory.com/136)
- [(ì˜ìƒ) ë­ë³¼ê¹Œ? : ë„¤ì´ë²„ AiRS ì¸ê³µì§€ëŠ¥ ì½˜í…ì¸  ì¶”ì²œì˜ ì§„í™”](https://tv.naver.com/v/16968202)
- [ë…¼ë¬¸ ë¦¬ë·° A Contextual-Bandit Approach to Personalized News Article Recommendation](https://leehyejin91.github.io/post-contextual_bandit/)
- [RecSys Challenge 2023 Homepage](https://www.recsyschallenge.com/2023/)


### 6.4.5 Movie Rec
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()

### 6.4.6 Recsys Recent Trends
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()
- []()

## 6.5 Generative AI
- [LLM ëª¨ë¸ íŠœë‹, í•˜ë‚˜ì˜ GPUë¡œ ê°€ëŠ¥í• ê¹Œ? Parameter Efficient Fine-Tuning(PEFT)ì„ ì†Œê°œí•©ë‹ˆë‹¤!](https://devocean.sk.com/blog/techBoardDetail.do?ID=164779&boardType=techBlog)
- [Alpaca í™ˆí˜ì´ì§€](https://crfm.stanford.edu/2023/03/13/alpaca.html)


## 6.6 Product Serving
- [Uberì˜ Michelangelo í”Œë«í¼ì— ê´€í•œ ê¸€ë¡œ, ëŒ€ê·œëª¨ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„œë¹™ ë°©ë²•ì— ëŒ€í•œ í†µì°°ì„ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://www.uber.com/en-KR/blog/scaling-michelangelo/)
- [Machine learning is going real-time](https://huyenchip.com/2020/12/27/real-time-machine-learning.html)
- [ì˜ì¹´ì˜ Airflow êµ¬ì¶•ê¸°](https://tech.socarcorp.kr/data/2021/06/01/data-engineering-with-airflow.html)
- [ì˜ì¹´ì˜ Airflow êµ¬ì¶•ê¸°2](https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html)
- [ë²„í‚·í”Œë ˆì´ìŠ¤ Airflow ë„ì…ê¸°](https://www.bucketplace.com/post/2021-04-13-%EB%B2%84%ED%82%B7%ED%94%8C%EB%A0%88%EC%9D%B4%EC%8A%A4-airflow-%EB%8F%84%EC%9E%85%EA%B8%B0/)
- [ë¼ì¸ ì—”ì§€ë‹ˆì–´ë§ Airflow on Kubernetes](https://engineering.linecorp.com/ko/blog/data-engineering-with-airflow-k8s-1)
- [Day1, 2-2. ê·¸ëŸ° REST APIë¡œ ê´œì°®ì€ê°€](https://www.youtube.com/watch?v=RP_f5dMoHFc)
- [HTTP response status codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Advanced User Guide for FastAPI](https://fastapi.tiangolo.com/advanced/)
- [Awesome-fastapi](https://github.com/mjhea0/awesome-fastapi)
- [ë„ì»¤(Docker) ì…ë¬¸í¸: ì»¨í…Œì´ë„ˆ ê¸°ì´ˆë¶€í„° ì„œë²„ ë°°í¬ê¹Œì§€](https://www.44bits.io/ko/post/easy-deploy-with-docker)
- [GCP ê³µì‹ ë¬¸ì„œ](https://cloud.google.com/docs?_gl=1*1qvbnv0*_up*MQ..&gclid=CjwKCAiA9bq6BhAKEiwAH6bqoH2F6QSWY2FuBmbvo00dn9Q17vhlVZWt-IHvBB4JCmDoHUTjymDqQhoCnygQAvD_BwE&gclsrc=aw.ds&hl=ko)
- [AWSë¥¼ ì´ìš©í•œ MLOps êµ¬ì¶• ì‚¬ë¡€ ì‚´í´ë³´ê¸°](https://aws.amazon.com/ko/blogs/tech/aws-mlops-use-case/)
- [MLOps Principles - Automation](https://ml-ops.org/content/mlops-principles#automation)
- [Experiments Tracking](https://ml-ops.org/content/mlops-principles#reproducibility)
- [Reproducibility](https://ml-ops.org/content/mlops-principles#reproducibility)
- [Data Engineer Jobs](https://www.linkedin.com/jobs/data-engineer-jobs/)

## 6.7 ìµœì í™”/ê²½ëŸ‰í™”
- [ Softmax Temperature](https://medium.com/@harshit158/softmax-temperature-5492e4007f71)
- [Lecture 10 - Knowledge Distillation | MIT 6.S965](https://www.youtube.com/watch?v=tT9Lnt6stwA)
- [ A brief overview of Imitation Learning](https://smartlabai.medium.com/a-brief-overview-of-imitation-learning-8a8a75c44a9c)
- [Dynamic Quantization](https://pytorch.org/tutorials/recipes/recipes/dynamic_quantization.html)
- [ë”¥ëŸ¬ë‹ì˜ Quantization (ì–‘ìí™”)ì™€ Quantization Aware Training:](https://gaussian37.github.io/dl-concept-quantization/#qat-quantization-aware-training-%EB%B0%A9%EB%B2%95-1)
- [Transfer Learning for Computer Vision Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [Brief Overview of Parallelism Strategies](https://afmck.in/posts/2023-02-26-parallelism/)
- [Data Parallelism on CNN:](https://siboehm.com/articles/22/data-parallel-training)
- [Pipeline Parallelism Algorithm](https://siboehm.com/articles/22/pipeline-parallel-training)
- [ë‹¨ì¼ ë¨¸ì‹ ì„ ì‚¬ìš©í•œ ëª¨ë¸ ë³‘ë ¬í™” ëª¨ë²” ì‚¬ë¡€](https://tutorials.pytorch.kr/intermediate/model_parallel_tutorial.html)

# 7. ğŸ“ŒContribution í•˜ëŠ” ë°©ë²•

## 7.1 Forkë¥¼ í•œë‹¤.
- ì›ë³¸ ì €ì¥ì†Œë¥¼ ë‚´ ê³„ì •ìœ¼ë¡œ ë³µì‚¬(Fork)

## 7.2 PRë¥¼ ë³´ë‚¸ë‹¤.
- Forkí•œ ì €ì¥ì†Œì—ì„œ ë³€ê²½ ë‚´ìš©ì„ ì‘ì—…í•œ ë’¤ Pull Request(Pull Request)ë¥¼ ìƒì„±

## 7.3 Approveë¥¼ ë°›ìœ¼ë©´ Merge!
- ë¦¬ë·° í›„ ìŠ¹ì¸ì„ ë°›ìœ¼ë©´ ì›ë³¸ ì €ì¥ì†Œì— ë³€ê²½ì‚¬í•­ì´ ë³‘í•©(Merge)

>ì´ ë¬¸ì„œëŠ” ê³„ì† ì—…ë°ì´íŠ¸ ì˜ˆì •ì…ë‹ˆë‹¤.
ê¶ê¸ˆí•œ ì‚¬í•­ì´ë‚˜ ì œì•ˆì´ ìˆë‹¤ë©´ Issue í˜¹ì€ Pull Requestë¡œ ì•Œë ¤ì£¼ì„¸ìš”!
ê°ì‚¬í•©ë‹ˆë‹¤.

## 8. ğŸ“ŒUpdates (Changelog)

| ë‚ ì§œ       | ë³€ê²½ ì‚¬í•­                                                                                                         |
|------------|-------------------------------------------------------------------------------------------------------------------|
| 2025-01-01 | ğŸ¨ **CV ì—…ë°ì´íŠ¸**<br/>- CV ì„¹ì…˜ ë…¼ë¬¸ ëª©ë¡ì„ ì¶”ê°€í•˜ê³  ê¹”ë”í•˜ê²Œ ì •ë ¬í–ˆìŠµë‹ˆë‹¤.                                        |
| 2025-01-02 | âœ¨ **NLP ì´ë¡  ì„¹ì…˜ ì—…ë°ì´íŠ¸**<br/>- NLP ì´ë¡  íŒŒíŠ¸ì— ì£¼ìš” ë…¼ë¬¸ ë° ë ˆí¼ëŸ°ìŠ¤ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.                           |
| 2025-01-04 | ğŸ¨ **CV Recent Trends ì„¹ì…˜ ì—…ë°ì´íŠ¸**<br/>- CV recent trends ì„¹ì…˜ì— ìµœê·¼ ë…¼ë¬¸ ëª©ë¡ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. |
| 2025-01-13 | âœ¨ **NLP ê¸°ì´ˆ í”„ë¡œì íŠ¸ ì„¹ì…˜ ì—…ë°ì´íŠ¸**<br/>- NLP ê¸°ì´ˆ í”„ë¡œì íŠ¸ íŒŒíŠ¸ì— ì£¼ìš” ë…¼ë¬¸ ë° ë ˆí¼ëŸ°ìŠ¤ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.          |
| 2025-01-13 | ğŸŒ± **Recsys ì´ë¡  ë° ML ê¸°ì´ˆ í”„ë¡œì íŠ¸ ì„¹ì…˜ ì—…ë°ì´íŠ¸**<br/>- Recsys ê¸°ì´ˆ í”„ë¡œì íŠ¸ íŒŒíŠ¸ì— ì£¼ìš” ë…¼ë¬¸ ë° ë ˆí¼ëŸ°ìŠ¤ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.      |
| 2025-01-14 | âœ¨ **NLP MRC & Data-Centric ì„¹ì…˜ ì—…ë°ì´íŠ¸**<br/>- NLP ê¸°ì´ˆ í”„ë¡œì íŠ¸ íŒŒíŠ¸ì— ì£¼ìš” ë…¼ë¬¸ ë° ë ˆí¼ëŸ°ìŠ¤ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.          |
| 2025-01-14 | ğŸŒ± **Recsys Competitive DS & Recsys ê¸°ì´ˆí”„ë¡œì íŠ¸ ì„¹ì…˜ ì—…ë°ì´íŠ¸**<br/>- Recsys ê¸°ì´ˆ í”„ë¡œì íŠ¸ íŒŒíŠ¸ì— ì£¼ìš” ë…¼ë¬¸ ë° ë ˆí¼ëŸ°ìŠ¤ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.      |


